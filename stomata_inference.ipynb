{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"stomata_inference.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNu+joZ0LDnUch4dkhh0Us7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IifoEynGbBSX","colab_type":"text"},"source":["Author: Hiranya Jayakody. April 2020.\n","\n","Code developed for Smart Robotics Viticulture Group, UNSW, Sydney.\n","\n","Neural Network based on Matterport implementation of Mask-RCNN at https://github.com/matterport/Mask_RCNN"]},{"cell_type":"markdown","metadata":{"id":"qCvl0TpVhWai","colab_type":"text"},"source":["### PART 1: Install Mask-RCNN repo from Matterport"]},{"cell_type":"code","metadata":{"id":"W4Ndsg-3bIjN","colab_type":"code","colab":{}},"source":["!git clone https://github.com/matterport/Mask_RCNN.git\n","!pip install -r 'Mask_RCNN/requirements.txt'\n","!cd Mask_RCNN ; python setup.py install"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-6Ga523wbcD2","colab_type":"code","colab":{}},"source":["!pip show mask-rcnn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArgHtsc8beX-","colab_type":"code","colab":{}},"source":["!pip install tensorflow==1.5.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PocPNLe3biAE","colab_type":"code","colab":{}},"source":["!pip install keras==2.1.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ds-jzLO4wNWm","colab_type":"code","colab":{}},"source":["!pip install opencv-python==3.4.9.31"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HAUPaJ0cfyQe","colab_type":"code","colab":{}},"source":["#mount your google drive if necessary\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GnePMb0WbJOS","colab_type":"text"},"source":["### PART 2: Set-up Mask-RCNN for inference"]},{"cell_type":"code","metadata":{"id":"3r2zo_YlEWIy","colab_type":"code","colab":{}},"source":["# restart runtime if 'No module named 'mrcnn'' error occurs\n","\n","import os\n","import cv2\n","import glob\n","import sys\n","import json\n","import datetime\n","import numpy as np\n","import skimage.draw\n","import imutils\n","import imgaug\n","import statistics as st\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from mrcnn.config import Config\n","from mrcnn import visualize\n","from mrcnn import model as modellib, utils\n","from matplotlib import pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GzC6JaEPEegD","colab_type":"code","colab":{}},"source":["CWD = 'drive/My Drive/Colab Notebooks/'\n","STOMATA_WEIGHTS_PATH = os.path.join(CWD,'2020_mask_rcnn_stomata_51.h5') \n","WEIGHT_FILE_NAME = 'stomata'\n","CLASS_NAME = 'stomata'\n","DATASET_DIR = os.path.join(CWD,'images/')\n","INPUT_IMG_DIR = os.path.join(DATASET_DIR,'test/') \n","OUTPUT_IMG_DIR = os.path.join(DATASET_DIR,'results/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UNxWWbIbbPBV","colab_type":"code","colab":{}},"source":["#create config for inference\n","class InferenceConfig(Config):\n","    # Set batch size to 1 since we'll be running inference on\n","    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n","    NAME = CLASS_NAME #provide a suitable name\n","    NUM_CLASSES = 1+1 #background+number of classes\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","    RPN_ANCHOR_SCALES = (12,24,48,96,192) #anchor box scales for the application\n","    DETECTION_MIN_CONFIDENCE = 0.6 #set min confidence threshold\n","    DETECTION_MAX_INSTANCES = 500\n","    POST_NMS_ROIS_INFERENCE = 10000\n","    IMAGE_MAX_DIM = 1024\n","    IMAGE_MIN_DIM = 800\n","    MEAN_PIXEL = np.array([133.774, 133.774, 133.774]) #DEFAULT VALUES FOR STOMATA MODEL. Change as necessary. #matterport takes the input as RGB"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3dmNYfGeA6Q","colab_type":"code","colab":{}},"source":["#create inference object\n","inference_config = InferenceConfig()\n","inference_config.display()\n","\n","# Load the model in inference mode\n","model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=CWD)\n","model_path = STOMATA_WEIGHTS_PATH #os.path.join(CWD,'mask_rcnn_stomata.h5')\n","\n","print(\"Loading weights from \", model_path)\n","model.load_weights(model_path, by_name=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-9eVILPvbP_R","colab_type":"text"},"source":["### PART 3: Apply model to identify stomata"]},{"cell_type":"markdown","metadata":{"id":"dBZk-wAgFfsf","colab_type":"text"},"source":["3.1 Function Definitions"]},{"cell_type":"code","metadata":{"id":"vIcMsbB2eivy","colab_type":"code","colab":{}},"source":["# Statistical filter\n","\n","def stomata_filter(r_pd_):\n","    #stomata filer: This code filters out stomata like shapes which are of wrong size, using confidence measures.\n","    high_scores = r_pd_[\"scores\"][r_pd_[\"scores\"]>0.90]\n","            \n","    if len(high_scores) > 0:\n","        percentile_thres = np.min(high_scores)\n","    else:\n","        percentile_thres = np.percentile(r_pd_[\"scores\"], 95) #st.median(r_pd_[\"scores\"])\n","    \n","    high_conf_areas = r_pd_[\"areas\"][r_pd_[\"scores\"]>=percentile_thres] #conf_threshold\n","    high_conf_scores = r_pd_[\"scores\"][r_pd_[\"scores\"]>=percentile_thres]\n","    \n","    high_conf_avg_area = st.mean(high_conf_areas)\n","    \n","    above_avg = high_conf_areas[high_conf_areas>=high_conf_avg_area]\n","    below_avg = high_conf_areas[high_conf_areas<high_conf_avg_area]\n","    \n","    above_avg_conf = high_conf_scores[high_conf_areas>=high_conf_avg_area]\n","    below_avg_conf = high_conf_scores[high_conf_areas<high_conf_avg_area]\n","    \n","    #based on data length\n","    if len(above_avg) >= len(below_avg):\n","        optimal_area = np.percentile(above_avg, 50) #(st.mean(above_avg)+np.max(above_avg))/2.0 #can we use percentie \n","        st_size = 'LARGE'\n","    else:\n","        #smaller elements may not be stomata, so check for their overall confidence with respect to the confidence of larger areas\n","        if np.mean(above_avg_conf) >= np.mean(below_avg_conf) and len(above_avg) > 1:\n","            optimal_area = np.percentile(above_avg, 50)\n","            st_size = 'LARGE'\n","        elif len(above_avg) <=1 and np.max(above_avg_conf) > 0.985:\n","            optimal_area = np.percentile(above_avg, 50)\n","            st_size = 'LARGE'\n","        else:\n","            optimal_area = np.percentile(below_avg, 75)\n","            st_size = 'SMALL'\n","       \n","    if st_size == 'LARGE':\n","        indices_ = r_pd_[\"scores\"][np.logical_and(r_pd_[\"areas\"]> (optimal_area*0.55),r_pd_[\"areas\"]<1.5*optimal_area )].index.values.astype(int)\n","    else:\n","        indices_ = r_pd_[\"scores\"][np.logical_and(r_pd_[\"areas\"]> (optimal_area*0.65),r_pd_[\"areas\"]<1.5*optimal_area )].index.values.astype(int)\n","\n","    return indices_\n","    \n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IB5HnD4qe3_H","colab_type":"code","colab":{}},"source":["# Other supporting functions\n","\n","def get_filename(string_):\n","    #get image filename    \n","    start = string_.find('test/')+5\n","    end = string_.find('.jpg',start)\n","    filename = string_[start:end]\n","    return filename\n","\n","def hisEqulColor(img):\n","    #contrast limited histogram equalisation\n","    ycrcb=cv2.cvtColor(img,cv2.COLOR_BGR2YCR_CB)\n","    channels=cv2.split(ycrcb)\n","    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(25,25))\n","    channels[0] = clahe.apply(channels[0])\n","    cv2.merge(channels,ycrcb)\n","    cv2.cvtColor(ycrcb,cv2.COLOR_YCR_CB2BGR,img)\n","    return img\n","\n","def sharpenColor(img):\n","    #sharpen image\n","    kernel_sharpening = np.array([[-1,-1,-1], \n","                              [-1, 9,-1],\n","                              [-1,-1,-1]])\n","    img = cv2.filter2D(img, -1, kernel_sharpening)\n","    return img\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L0mZ7Zs9eTYc","colab_type":"text"},"source":["### PART 3A: Test on a single image ###"]},{"cell_type":"markdown","metadata":{"id":"TaqTIZmvLRUB","colab_type":"text"},"source":["Please Refer to Part 3B and remove the loop for the folder."]},{"cell_type":"markdown","metadata":{"id":"bdDGiGfvebtX","colab_type":"text"},"source":["### PART 3B: Test on an image folder"]},{"cell_type":"code","metadata":{"id":"a8jKDCt9eh6K","colab_type":"code","colab":{}},"source":["DATA_PATH = os.path.join(INPUT_IMG_DIR,'*jpg')\n","files = glob.glob(DATA_PATH)\n","\n","stomata_data = pd.DataFrame(columns=['filename','num_stomata','scores','areas'])\n","\n","print(cv2. __version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HeeX8Brufda_","colab_type":"code","colab":{}},"source":["counter = 0\n","for img in files:\n","    filename = get_filename(img)\n","    print(filename)\n","    image = cv2.imread(img)\n","    image = imutils.resize(image,width=1024)\n","    image_original = image\n","    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) #opnecv uses BGR convention\n","    \n","    \n","    #call histogram equalize function (optional)\n","    image = hisEqulColor(image)\n","    #image = sharpenColor(image)\n","    \n","    #convert to grayscale and save as a three channel jpeg then read it back and convert\n","    image_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","    cv2.imwrite('current_image.jpg', image_gray)\n","    \n","    image_new = cv2.imread('current_image.jpg')\n","    image = cv2.cvtColor(image_new,cv2.COLOR_BGR2RGB) #opnecv uses BGR convention\n","    image = imutils.resize(image,width=1024)\n","    \n","    #run the image through the model\n","    print(\"making predictions with Mask R-CNN...\")\n","    r = model.detect([image], verbose=1)[0]\n","    \n","    #create dataframe for ease of use\n","    r_pd = pd.DataFrame(columns=['class_id','scores', 'areas'])\n","        \n","    #create array to store areas\n","    num_stomata = len(r[\"scores\"])\n","  \n","    r_pd[\"class_ids\"] = r[\"class_ids\"]\n","    r_pd[\"scores\"] = r[\"scores\"]\n","               \n","    #retrieve area values from X,Y coordinates\n","    for i in range(0, len(r_pd[\"scores\"])): \n","        (startY,startX,endY,endX) = r[\"rois\"][i]\n","        r_pd[\"areas\"][i] = abs(startY-endY)*abs(startX-endX)\n","        \n","        \n","    #see how many stomata are on the image\n","    #1. If there are more than 2 stomata, do the following.\n","    #2. get the median score for confidence\n","    #3. get the average area for median and above\n","    #4. reject areas 90% or less than the average median area\n","    \n","    if num_stomata == 0:\n","        print(\"no stomata detected\")\n","        stomata_data.loc[counter] = [filename,num_stomata,0]\n","        counter +=1\n","        cv2.imwrite(OUTPUT_IMG_DIR+filename+'_000'+'.jpg', image)\n","        continue\n","    \n","    if num_stomata >= 2:\n","        \n","        indices = stomata_filter(r_pd)\n","        #indices = r_pd[\"scores\"][:].index.values.astype(int) #this ignores the statistical filter\n","\n","    else: \n","        indices = [0]\n","        \n","    print(indices)\n","            \n","    # loop over of the detected object's bounding boxes and masks\n","    areas = []\n","    for i in range(0, len(indices)):\n","        classID = r[\"class_ids\"][indices[i]]\n","        mask = r[\"masks\"][:, :, indices[i]]\n","        color = [0,0,0]\n","        areas.append(np.sum(mask == True))\n","\n","        #uncomment to visualize the pixel-wise mask of the object\n","        #image = visualize.apply_mask(image, mask, color, alpha=0.5)\n","        \n","        #visualize contours\n","        mask[mask ==True] = 1\n","        mask[mask == False] = 0\n","        mask = mask.astype(np.uint8)\n","        mask,contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","        cv2.drawContours(image_original,contours, 0, [0,255,0], 4)\n","    \n","    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n","\n","    for i in range(0,len(indices)):\n","        (startY,startX,endY,endX) = r[\"rois\"][indices[i]]\n","        classID = r[\"class_ids\"][indices[i]]\n","        label = classID\n","        score = r[\"scores\"][indices[i]]\n","        color = [255,0,0]\n","\n","        #uncomment to draw bounding box around stomata\n","        #cv2.rectangle(image_original,(startX,startY),(endX,endY),color,2)\n","\n","        #uncomment to print confidence value\n","        #text = \"{}: {:.3f}\".format(label,score)\n","        #y = startY - 10 if startY - 10 > 10 else startY + 10\n","        #cv2.putText(image_original,text,(startX,y),cv2.FONT_HERSHEY_SIMPLEX,0.8,color,2)\n","\n","    id_str= str(len(indices))\n","    stomata_data.loc[counter] = [filename,len(indices),r[\"scores\"][indices],areas]\n","    counter +=1\n","    cv2.imwrite(OUTPUT_IMG_DIR+filename+'_'+id_str.zfill(3)+'.jpg', image_original)\n","    \n","\n","stomata_data.to_csv(OUTPUT_IMG_DIR+'results.csv',encoding='utf-8', index=False)\n","    \n","    "],"execution_count":0,"outputs":[]}]}