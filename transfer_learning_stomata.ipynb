{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_learning_stomata.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO7R/oOyWhqjZyaZoCSTHDw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qjTJICpTIB3n","colab_type":"text"},"source":["Author: Hiranya Jayakody. April 2020.\n","\n","Code developed for Smart Robotics Viticulture Group, UNSW, Sydney.\n","\n","Neural Network based on Matterport implementation of Mask-RCNN at https://github.com/matterport/Mask_RCNN"]},{"cell_type":"markdown","metadata":{"id":"5KFe5Y7Tge2E","colab_type":"text"},"source":["### PART 1: Install Mask-RCNN repo from Matterport ###"]},{"cell_type":"code","metadata":{"id":"ssZKHHl0H49O","colab_type":"code","colab":{}},"source":["!git clone https://github.com/matterport/Mask_RCNN.git\n","!pip install -r 'Mask_RCNN/requirements.txt'\n","!cd Mask_RCNN ; python setup.py install"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9eL1H7OJErt","colab_type":"code","colab":{}},"source":["!pip show mask-rcnn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2Q-e0o9UtJs","colab_type":"code","colab":{}},"source":["!pip install tensorflow==1.5.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pbm4D7o3VpiO","colab_type":"code","colab":{}},"source":["!pip install keras==2.1.5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JAb6EDHDJRNu","colab_type":"text"},"source":["### PART 2: Set-up Mask-RCNN for training ###"]},{"cell_type":"code","metadata":{"id":"6FuFprz5JXSv","colab_type":"code","colab":{}},"source":["import os\n","import cv2\n","import glob\n","import sys\n","import json\n","import datetime\n","import numpy as np\n","import skimage.draw\n","import imutils\n","import imgaug\n","import statistics as st\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from mrcnn.config import Config\n","from mrcnn import visualize\n","from mrcnn import model as modellib, utils\n","from matplotlib import pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jF_L4bA1QS6d","colab_type":"code","colab":{}},"source":["#mount necessary folders\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q3EbwGA4KX7J","colab_type":"code","colab":{}},"source":["#define all directories\n","CWD = 'drive/My Drive/Colab Notebooks/'\n","STOMATA_WEIGHTS_PATH = os.path.join(CWD,'2020_mask_rcnn_stomata_51.h5')\n","WEIGHT_FILE_NAME = 'stomata'\n","CLASS_NAME = 'stomata'\n","DEFAULT_LOGS_DIR = os.path.join(CWD,'logs/')\n","DATASET_DIR = os.path.join(CWD,'images/')\n","TRAINING_IMG_DIR = os.path.join(DATASET_DIR,'train/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oxvfiq6mKixT","colab_type":"code","colab":{}},"source":["# Find mean pixel value for training\n","DATA_PATH = os.path.join(TRAINING_IMG_DIR,'*jpg')\n","training_files = glob.glob(DATA_PATH)\n","\n","avg_b = []\n","avg_g = []\n","avg_r = []\n","\n","print(DATA_PATH)\n","for img in training_files:\n","    image = cv2.imread(img)\n","    b, g, r = np.average(image, axis = (0,1))\n","    avg_b.append(b)\n","    avg_g.append(g)\n","    avg_r.append(r)\n","    \n","mean_b = np.average(avg_b[:])\n","mean_g = np.average(avg_g[:])\n","mean_r = np.average(avg_r[:])\n","\n","print([mean_b,mean_g,mean_r])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3YVrWrxOLMdq","colab_type":"code","colab":{}},"source":["#create custom config class for training\n","class CustomConfig(Config):\n","    NAME = CLASS_NAME #provide a suitable name\n","    IMAGES_PER_GPU = 2 #set to one for smaller GPUs\n","    NUM_CLASSES = 1+1 #background+number of classes\n","    STEPS_PER_EPOCH = 100 #number of training steps per epoch\n","    RPN_ANCHOR_SCALES =(12,24, 48, 96, 192) \n","    DETECTION_MAX_INSTANCES = 300\n","    DETECTION_MIN_CONFIDENCE = 0.6 \n","    LOSS_WEIGHTS = {'mrcnn_bbox_loss': 1.0, 'rpn_class_loss': 1.0, 'mrcnn_mask_loss': 1.0, 'mrcnn_class_loss': 1.0, 'rpn_bbox_loss': 1.0}\n","    IMAGE_MAX_DIM = 1024\n","    IMAGE_MIN_DIM = 800\n","    RPN_NMS_THRESHOLD = 0.9\n","    RPN_TRAIN_ANCHORS_PER_IMAGE = 1024\n","    MEAN_PIXEL = np.array([mean_r,mean_g,mean_b]) #matterport takes the input as RGB\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZatDpRTLnkJ","colab_type":"code","colab":{}},"source":["#add augmentation for input data\n","augmentation = imgaug.augmenters.Sometimes(4/6,imgaug.augmenters.OneOf(\n","                                            [ \n","                                            imgaug.augmenters.Affine(rotate=(-30, 30)),\n","                                            imgaug.augmenters.Affine(rotate=(-45, 45)), \n","                                            imgaug.augmenters.Affine(rotate=(-90, 90)), \n","                                            ]))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0TVagbBKLq6m","colab_type":"code","colab":{}},"source":["#create custom dataset class\n","class CustomDataset(utils.Dataset):\n","    def load_customdata(self, dataset_dir, subset):\n","        #subset can be either training or validation\n","        \n","        #We add the classes here.\n","        self.add_class(CLASS_NAME,1,CLASS_NAME) #add_class(self,source,class_id,class_name)\n","       \n","        assert subset in ['train','val']\n","        dataset_dir = os.path.join(dataset_dir,subset)\n","        \n","        #next step is to load the annotations\n","        annotations = json.load(open(os.path.join(dataset_dir,'via_region_data.json')))\n","        annotations = list(annotations.values())\n","        \n","        #skip unannotated images\n","        annotations = [a for a in annotations if a['regions']]\n","        \n","        for a in annotations:\n","            #get the x,y coordinates of points of the polygon\n","            if type(a['regions']) is dict:\n","                polygons = [r['shape_attributes'] for r in a['regions'].values()] \n","            else:\n","                polygons = [r['shape_attributes'] for r in a['regions']]\n","                \n","            # load_mask() requires the image size\n","            image_path = os.path.join(dataset_dir,a['filename'])\n","            image = skimage.io.imread(image_path)\n","            height,width = image.shape[:2]\n","\n","            self.add_image(CLASS_NAME, image_id = a['filename'], path=image_path, width=width, height=height, polygons=polygons) #add_image(self, source, image_id, path, **kwargs)\n","\n","    #override function for load_mask\n","    def load_mask(self, image_id):\n","        #this function generates instance masks for an image\n","        \n","        #if not a custom dataset image, delegate to parent class\n","        image_info = self.image_info[image_id]\n","        if image_info['source'] != CLASS_NAME:\n","            return super(self._class__,self).load_mask(image_id)\n","        \n","        #convert polygons to bitmap mask of shape\n","        info = self.image_info[image_id]\n","        mask = np.zeros([info['height'], info['width'],len(info['polygons'])], dtype= np.uint8)\n","        \n","        for i,p in enumerate(info['polygons']):\n","            rr,cc = skimage.draw.polygon(p['all_points_y'],p['all_points_x'])\n","            mask[rr,cc,i] = 1\n","            \n","        # return mask and class IDs. for 1 class we return 1s (CAN WE MODIFY THIS?)\n","        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n","    \n","    #overrids function for image_reference\n","    def image_reference(self, image_id):\n","        #returns the path of the image\n","        info = self.image_info[image_id]\n","        \n","        if info['source'] == CLASS_NAME:\n","            return info['path']\n","        else:\n","            super(self.__class__,self).image_reference(image_id)\n","            "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5X8GxL-BL7aq","colab_type":"code","colab":{}},"source":["#set-up training function\n","def train(model):\n","    #training dataset\n","    dataset_train = CustomDataset()\n","    dataset_train.load_customdata(DATASET_DIR, 'train') \n","    dataset_train.prepare()\n","    \n","    #validation dataset\n","    dataset_val = CustomDataset()\n","    dataset_val.load_customdata(DATASET_DIR, 'val') \n","    dataset_val.prepare()\n","    \n","    print('training network heads')\n","    #for transfer learning often training the heads layers should be enough. You can modify the number of epochs here.\n","    model.train(dataset_train, dataset_val, learning_rate = config.LEARNING_RATE, epochs = 40, layers='heads', augmentation = augmentation) \n","    #otherwise layers = 'all' or 'heads'\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RkzY8_y2Nlbj","colab_type":"text"},"source":["### PART3: Execute training\n"]},{"cell_type":"code","metadata":{"id":"qfQzHUHsMGoe","colab_type":"code","colab":{}},"source":["#initialize config and model for training\n","config = CustomConfig()\n","config.display()\n","\n","#create model and load default weights from stomata model\n","model = modellib.MaskRCNN(mode='training',config=config, model_dir= DEFAULT_LOGS_DIR)\n","print('loading weights', STOMATA_WEIGHTS_PATH)\n","model.load_weights(STOMATA_WEIGHTS_PATH, by_name=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfsxP9BTMiA5","colab_type":"code","colab":{}},"source":["train(model)"],"execution_count":0,"outputs":[]}]}
